import os
import pandas as pd
import traceback
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError

# Usar la URL pÃºblica para asegurar misma base que DBeaver
DB_URL = os.getenv("DATABASE_PUBLIC_URL") or os.getenv("DATABASE_URL")
if not DB_URL:
    raise RuntimeError("âŒ No se encontrÃ³ DATABASE_PUBLIC_URL ni DATABASE_URL. VerificÃ¡ las variables de entorno en Railway.")

engine = create_engine(DB_URL)
print(f"ğŸ”— Usando URL: {DB_URL}")

def procesar_parquet_por_chunks(ruta_parquet="/app/data_fuentes/ffmm_merged.parquet",
                                tabla_destino="fondos_mutuos",
                                chunk_size=50000):
    print("ğŸš€ Iniciando carga batch por chunks desde parquet...")
    print(f"ğŸ“‚ Leyendo parquet: {ruta_parquet}")

    try:
        df = pd.read_parquet(ruta_parquet, engine="pyarrow")
        print(f"âœ… Dataframe cargado: {len(df)} filas")
        print(f"ğŸ“ Columnas originales: {list(df.columns)}")

        # ğŸ”„ Normalizar nombres de columnas
        df.columns = (
            df.columns
            .str.replace(r'[^\w]+', '_', regex=True)  # reemplazar puntos y caracteres raros por "_"
            .str.lower()  # pasar todo a minÃºsculas
        )
        print(f"ğŸ“ Columnas normalizadas: {list(df.columns)}")

    except Exception as e:
        print(f"âŒ Error al leer parquet: {e}")
        return

    try:
        # ğŸ”„ Drop de tabla al inicio
        with engine.begin() as conn:
            print("âš ï¸ Eliminando tabla fondos_mutuos si existe...")
            conn.execute(text(f'DROP TABLE IF EXISTS "{tabla_destino}";'))

        total = len(df)
        for i in range(0, total, chunk_size):
            chunk = df.iloc[i:i+chunk_size]
            print(f"ğŸ”¹ Insertando chunk {i//chunk_size + 1}: {len(chunk)} filas")

            if i == 0:
                try:
                    with engine.begin() as conn:
                        chunk.to_sql(tabla_destino, conn, if_exists="replace", index=False, method='multi')
                        print("âœ… Tabla creada e insertado primer chunk")
                except Exception:
                    print("âŒ Error en primer chunk:")
                    traceback.print_exc()
                    break
            else:
                try:
                    with engine.begin() as conn:
                        chunk.to_sql(tabla_destino, conn, if_exists="append", index=False, method='multi')
                except SQLAlchemyError as e:
                    print(f"âš ï¸ Error al insertar chunk: {e}")
                    break

        with engine.connect() as conn:
            print("ğŸ§¹ Ejecutando VACUUM FULL ANALYZE...")
            conn.execute(text(f'VACUUM FULL ANALYZE "{tabla_destino}";'))
            print("âœ… VACUUM completado")

    except Exception as e:
        print(f"âŒ Error general en procesamiento: {e}")

if __name__ == "__main__":
    procesar_parquet_por_chunks()
